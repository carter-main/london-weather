{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d5223a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "809658db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in London weather dataset\n",
    "df = pd.read_csv(\"/Users/cartermain/Downloads/london_weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7cbef9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                   0\n",
      "cloud_cover           19\n",
      "sunshine               0\n",
      "global_radiation      19\n",
      "max_temp               6\n",
      "mean_temp             36\n",
      "min_temp               2\n",
      "precipitation          6\n",
      "pressure               4\n",
      "snow_depth          1441\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# counting null values\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8568d8b0",
   "metadata": {},
   "source": [
    "Going to need to replace null values for snow depth with 0. Let's start with days that had 0 recorded precipitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "47dfa891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758\n"
     ]
    }
   ],
   "source": [
    "# counting rows that meet this criteria\n",
    "print(sum((df[\"snow_depth\"].isnull()) & (df[\"precipitation\"] == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "af84e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing all null snow_depth days that had 0 precipitation with 0 for snow_depth\n",
    "df.loc[(df[\"snow_depth\"].isnull()) & (df[\"precipitation\"] == 0), \"snow_depth\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2521f2d1",
   "metadata": {},
   "source": [
    "Now, we can replace all days with a min temp above the temperature needed for snow to accumulate on the ground (5Â° C according to the National Snow & Ice Data Center: https://nsidc.org/learn/parts-cryosphere/snow/science-snow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a077fe49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625\n"
     ]
    }
   ],
   "source": [
    "# identifying number of rows that meet this criteria\n",
    "print(sum((df[\"snow_depth\"].isnull()) & (df[\"min_temp\"] > 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f47c0bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing null values with 0 for snow_depth\n",
    "df.loc[(df[\"snow_depth\"].isnull()) & (df[\"min_temp\"] > 5), \"snow_depth\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "51dc5888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                 0\n",
      "cloud_cover         19\n",
      "sunshine             0\n",
      "global_radiation    19\n",
      "max_temp             6\n",
      "mean_temp           36\n",
      "min_temp             2\n",
      "precipitation        6\n",
      "pressure             4\n",
      "snow_depth          58\n",
      "dtype: int64\n",
      "15341\n"
     ]
    }
   ],
   "source": [
    "# taking a look at fresh null count after changes\n",
    "print(df.isnull().sum())\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e081efc",
   "metadata": {},
   "source": [
    "We've now gotten null value count down to less than 1% of the original dataset size so I am comfortable dropping remaining rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "74d71667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows with null values\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055639cc",
   "metadata": {},
   "source": [
    "Now, let's check for some outliers before getting into our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3de4ad32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               date   cloud_cover      sunshine  global_radiation  \\\n",
      "count  1.520700e+04  15207.000000  15207.000000      15207.000000   \n",
      "mean   1.999494e+07      5.269678      4.349464        119.022555   \n",
      "std    1.209193e+05      2.067057      4.022147         88.942076   \n",
      "min    1.979010e+07      0.000000      0.000000          8.000000   \n",
      "25%    1.989061e+07      4.000000      0.500000         41.000000   \n",
      "50%    1.999112e+07      6.000000      3.500000         95.000000   \n",
      "75%    2.010061e+07      7.000000      7.200000        186.000000   \n",
      "max    2.020123e+07      9.000000     16.000000        402.000000   \n",
      "\n",
      "           max_temp     mean_temp      min_temp  precipitation       pressure  \\\n",
      "count  15207.000000  15207.000000  15207.000000   15207.000000   15207.000000   \n",
      "mean      15.402223     11.493293      7.576511       1.666739  101536.427303   \n",
      "std        6.549930      5.723116      5.323478       3.736406    1048.041358   \n",
      "min       -6.200000     -7.600000    -11.800000       0.000000   95960.000000   \n",
      "25%       10.500000      7.100000      3.600000       0.000000  100920.000000   \n",
      "50%       15.000000     11.400000      7.800000       0.000000  101620.000000   \n",
      "75%       20.300000     16.000000     11.800000       1.600000  102240.000000   \n",
      "max       37.900000     29.000000     22.300000      61.800000  104820.000000   \n",
      "\n",
      "         snow_depth  \n",
      "count  15207.000000  \n",
      "mean       0.034458  \n",
      "std        0.520774  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        0.000000  \n",
      "75%        0.000000  \n",
      "max       22.000000  \n"
     ]
    }
   ],
   "source": [
    "# checking max and min values relative to mean, 25%, and 75%\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "76c01f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of columns to check for outliers in (ignoring snow depth becaude 25% and 75% are 0)\n",
    "columns_to_inspect = [\"cloud_cover\", \"sunshine\", \"global_radiation\", \"max_temp\", \"mean_temp\", \"min_temp\", \"precipitation\", \"pressure\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "15b9090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using interquartile range to turn outliers into null values\n",
    "for feature in columns_to_inspect:\n",
    "    # looking at top and bottom 100 values for each feature to expedite the loop and save space\n",
    "    for x in df[feature].sort_values(ascending = False)[0:100]:\n",
    "        q75 = df[feature].describe()[\"75%\"]\n",
    "        q25 = df[feature].describe()[\"25%\"]\n",
    "        intr_qr = q75 - q25\n",
    "        max = q75 + (1.5 * intr_qr)\n",
    "        min = q25 - (1.5 * intr_qr)\n",
    "        if x > max or x < min:\n",
    "            df.loc[df[feature] == x, feature] = np.nan\n",
    "    for x in df[feature][df[feature].notnull() == True].sort_values(ascending = False)[-100:]:\n",
    "        if x > max or x < min:\n",
    "            df.loc[df[feature] == x, feature] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "753cce92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                  0\n",
      "cloud_cover           0\n",
      "sunshine              0\n",
      "global_radiation      0\n",
      "max_temp             11\n",
      "mean_temp             1\n",
      "min_temp              7\n",
      "precipitation       408\n",
      "pressure            293\n",
      "snow_depth            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# checking null count after loop\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a88a07a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping na values\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "97b1aa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               date   cloud_cover     sunshine  global_radiation  \\\n",
      "count  1.450900e+04  14509.000000  14509.00000      14509.000000   \n",
      "mean   1.999463e+07      5.224895      4.45693        121.255014   \n",
      "std    1.207134e+05      2.074654      4.04366         89.389908   \n",
      "min    1.979010e+07      0.000000      0.00000         10.000000   \n",
      "25%    1.989061e+07      4.000000      0.50000         43.000000   \n",
      "50%    1.999103e+07      6.000000      3.70000         99.000000   \n",
      "75%    2.010052e+07      7.000000      7.30000        190.000000   \n",
      "max    2.020123e+07      9.000000     16.00000        402.000000   \n",
      "\n",
      "           max_temp     mean_temp      min_temp  precipitation       pressure  \\\n",
      "count  14509.000000  14509.000000  14509.000000   14509.000000   14509.000000   \n",
      "mean      15.520367     11.549631      7.590950       1.177304  101612.707285   \n",
      "std        6.548122      5.729887      5.326527       2.262090     961.825556   \n",
      "min       -4.000000     -5.400000     -8.500000       0.000000   99030.000000   \n",
      "25%       10.700000      7.200000      3.500000       0.000000  101000.000000   \n",
      "50%       15.300000     11.500000      7.900000       0.000000  101670.000000   \n",
      "75%       20.400000     16.100000     11.800000       1.200000  102270.000000   \n",
      "max       35.000000     29.000000     22.300000      11.900000  104180.000000   \n",
      "\n",
      "         snow_depth  \n",
      "count  14509.000000  \n",
      "mean       0.031636  \n",
      "std        0.487964  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        0.000000  \n",
      "75%        0.000000  \n",
      "max       22.000000  \n"
     ]
    }
   ],
   "source": [
    "# checking how these drops changed each feature\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7181af39",
   "metadata": {},
   "source": [
    "Now that we have gotten rid of outliers, we can run our linear regression with scaled data to predict pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3f81915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting features\n",
    "features = df[[\"date\", \"pressure\", \"cloud_cover\", \"global_radiation\", \"max_temp\", \"mean_temp\", \"min_temp\", \"precipitation\", \"snow_depth\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cae6bf9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.69742021,  0.33547089, -1.57552003, ..., -2.84262071,\n",
       "        -0.36037083, 18.59207728],\n",
       "       [-1.69741192,  0.96137317,  0.3588995 , ..., -2.84262071,\n",
       "        -0.49426323, 16.51908968],\n",
       "       [-1.69740364,  0.48449524, -0.12470538, ..., -2.78609674,\n",
       "        -0.49426323,  8.22713926],\n",
       "       ...,\n",
       "       [ 1.70822017, -2.71456088,  0.84250438, ..., -1.22226685,\n",
       "        -0.49426323, -0.06481116],\n",
       "       [ 1.70822845, -1.35347178,  0.3588995 , ..., -1.44836274,\n",
       "        -0.49426323, -0.06481116],\n",
       "       [ 1.70823673, -1.05542308,  0.84250438, ..., -2.01360246,\n",
       "        -0.49426323, -0.06481116]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaling feature set\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "78927d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test splitting with random state of 42\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, df[\"sunshine\"], train_size = 0.7, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c251f7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8762240473059097\n"
     ]
    }
   ],
   "source": [
    "# training and scoring model\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "print(model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f36519f",
   "metadata": {},
   "source": [
    "Time to run RFE to see which features we can drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "db582dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8751743916548861 6\n"
     ]
    }
   ],
   "source": [
    "# running via a for loop to test every possible number of features and only keep if it resulted in a 10%+ increase to save computational space\n",
    "max_score = 0.01\n",
    "best_x = 0\n",
    "for x in range(1,len(features.columns) + 1):\n",
    "    rfe = RFE(estimator = model, n_features_to_select = x)\n",
    "    rfe.fit(x_train, y_train)\n",
    "    score = rfe.score(x_test, y_test)\n",
    "    if (score - max_score) / max_score > .10:\n",
    "        max_score = score\n",
    "        best_x = x\n",
    "print(max_score, best_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8d907ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True  True  True  True  True  True False]\n"
     ]
    }
   ],
   "source": [
    "# finding out which features RFE decided to keep and drop\n",
    "rfe = RFE(estimator = model, n_features_to_select = best_x)\n",
    "rfe.fit(x_train, y_train)\n",
    "rfe.score(x_test, y_test)\n",
    "print(rfe.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "81dc9c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting column names of features kept by RFE\n",
    "kept_features = []\n",
    "y = 0\n",
    "for kept in rfe.support_:\n",
    "    if kept == True:\n",
    "        kept_features.append(features.columns[y])\n",
    "    y += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "602c1419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating revised feature set\n",
    "features_2 = df[kept_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3e88b894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.55447909, -0.77477875, -2.01902502, -2.73132254, -2.83326642,\n",
       "        -0.34363378],\n",
       "       [ 0.37361983, -1.05446202, -2.12592958, -2.46952827, -2.83326642,\n",
       "        -0.5204675 ],\n",
       "       [-0.1084049 , -1.21108465, -2.17174582, -2.50443418, -2.77694261,\n",
       "        -0.5204675 ],\n",
       "       ...,\n",
       "       [ 0.37361983, -0.90902672, -1.66776717, -1.5619748 , -1.29374877,\n",
       "        -0.5204675 ],\n",
       "       [ 0.37361983, -1.11039867, -1.51504637, -1.54452185, -1.44394561,\n",
       "        -0.5204675 ],\n",
       "       [ 0.85564456, -0.9761507 , -2.14120166, -2.15537515, -2.00718378,\n",
       "        -0.5204675 ]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaling new features set \n",
    "scaler_2 = StandardScaler()\n",
    "scaler_2.fit_transform(features_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5075d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resplitting with new feature set keeping random state as 42\n",
    "x_train_2, x_test_2, y_train_2, y_test_2 = train_test_split(features_2, df[\"sunshine\"], train_size = 0.7, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "03463a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8751743916548861\n"
     ]
    }
   ],
   "source": [
    "# retraining model with revised feature set\n",
    "model.fit(x_train_2, y_train_2)\n",
    "print(model.score(x_test_2, y_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8c1db62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running a for loop to test train sizes in 0.05 increments and find the top performing train size\n",
    "best_split = 0\n",
    "best_score = 0\n",
    "for x in np.linspace(0, 1, 21):\n",
    "    if x == 0 or x == 1:\n",
    "        continue\n",
    "    else: \n",
    "        x_train_3, x_test_3, y_train_3, y_test_3 = train_test_split(features_2, df[\"sunshine\"], train_size = x, random_state = 42)\n",
    "        model.fit(x_train_3, y_train_3)\n",
    "        score = model.score(x_test_3, y_test_3)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_split = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2be858f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8841681084240293 0.8500000000000001\n"
     ]
    }
   ],
   "source": [
    "# finding best performers\n",
    "print(best_score, best_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8220e5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resplitting revised feature set at best train size\n",
    "best_x_train, best_x_test, best_y_train, best_y_test = train_test_split(features_2, df[\"sunshine\"], train_size = best_split, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5ec8ac23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8841681084240293\n"
     ]
    }
   ],
   "source": [
    "# retraining our model one final time with this new split\n",
    "model.fit(best_x_train, best_y_train)\n",
    "print(model.score(best_x_test, best_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e80dc35",
   "metadata": {},
   "source": [
    "Lastly, let's check the coefficients of each feature for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "aafd1a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloud_cover: -0.74\n",
      "global_radiation: 0.03\n",
      "max_temp: -0.09\n",
      "mean_temp: 0.15\n",
      "min_temp: -0.14\n",
      "precipitation: -0.05\n"
     ]
    }
   ],
   "source": [
    "# running a for loop to print feature name and rounded coefficient\n",
    "x = 0\n",
    "for feature in features_2.columns:\n",
    "    print(feature + \": \" + str(round(model.coef_[x],2)))\n",
    "    x += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
